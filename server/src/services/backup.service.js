/**
 * PostgreSQL/SQLite Â§á‰ªΩÊúçÂä°
 * ÊîØÊåÅ PostgreSQL ÈÄªËæëÂ§á‰ªΩ (pg_dump) Âíå SQLite Êñá‰ª∂Â§á‰ªΩ
 * Ëá™Âä®Ê£ÄÊµãÊï∞ÊçÆÂ∫ìÁ±ªÂûãÂπ∂‰ΩøÁî®ÈÄÇÂΩìÁöÑÂ§á‰ªΩÁ≠ñÁï•
 */

const fs = require('fs')
const path = require('path')
const { exec } = require('child_process')
const { promisify } = require('util')
const execAsync = promisify(exec)

const getBackupsDir = () => path.join(__dirname, '..', '..', 'backups')

const ensureDir = (dir) => {
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true })
}

/**
 * Ëß£ÊûêÊï∞ÊçÆÂ∫ìËøûÊé•Â≠óÁ¨¶‰∏≤
 * ÊîØÊåÅ PostgreSQL: postgresql://user:password@host:port/database
 * ÊîØÊåÅ SQLite: file:./dev.db
 */
const parseConnectionString = () => {
  const url = process.env.DATABASE_URL || ''
  
  // SQLite Ê†ºÂºè
  if (url.startsWith('file:')) {
    return { type: 'sqlite', path: url.slice(5) }
  }
  
  // PostgreSQL Ê†ºÂºè
  try {
    const parsed = new URL(url)
    return {
      type: 'postgresql',
      host: parsed.hostname || 'localhost',
      port: parsed.port || '5432',
      user: parsed.username || 'postgres',
      password: parsed.password || '',
      database: parsed.pathname.slice(1) || 'blog',
      ssl: parsed.searchParams.get('sslmode') || undefined
    }
  } catch (e) {
    console.error('Êó†Ê≥ïËß£Êûê DATABASE_URL:', e.message)
    return null
  }
}

/**
 * Ëé∑ÂèñÊï∞ÊçÆÂ∫ìÁ±ªÂûã
 */
const getDatabaseType = () => {
  const config = parseConnectionString()
  return config?.type || 'unknown'
}

/**
 * PostgreSQL Â§á‰ªΩ - ‰ΩøÁî® pg_dump
 */
const backupPostgres = async () => {
  const config = parseConnectionString()
  if (!config || config.type !== 'postgresql') {
    throw new Error('Êó†ÊïàÁöÑ PostgreSQL ÈÖçÁΩÆ')
  }

  const backupsDir = getBackupsDir()
  ensureDir(backupsDir)

  const timestamp = new Date().toISOString().replace(/[-:T.Z]/g, '').slice(0, 14)
  const filename = `pg-backup-${timestamp}.sql`
  const filepath = path.join(backupsDir, filename)

  const env = {
    ...process.env,
    PGPASSWORD: config.password,
    PGHOST: config.host,
    PGPORT: config.port,
    PGUSER: config.user,
    PGDATABASE: config.database
  }

  try {
    const { stdout } = await execAsync(
      `pg_dump --clean --if-exists --no-owner --no-privileges --format=plain`,
      { env, maxBuffer: 100 * 1024 * 1024 }
    )
    await fs.promises.writeFile(filepath, stdout)
    console.log(`‚úÖ PostgreSQL Â§á‰ªΩÂÆåÊàê: ${filename}`)
    return filename
  } catch (error) {
    // ÂõûÈÄÄÂà∞ Prisma ÈÄªËæëÂ§á‰ªΩ
    console.warn('pg_dump Â§±Ë¥•Ôºå‰ΩøÁî® Prisma Â§á‰ªΩ:', error.message)
    return await backupWithPrisma(backupsDir, timestamp)
  }
}

/**
 * Prisma ÈÄªËæëÂ§á‰ªΩ - ÂØºÂá∫ÊâÄÊúâË°®Êï∞ÊçÆ‰∏∫ JSON
 */
const backupWithPrisma = async (backupsDir, timestamp) => {
  const { PrismaClient } = require('@prisma/client')
  const prisma = global.prisma || new PrismaClient()

  const tables = [
    'user', 'category', 'tag', 'post', 'comment', 'commentLike',
    'bookmarkCollection', 'bookmark', 'siteSettings', 'profile',
    'resource', 'project', 'column', 'columnNode',
    'operationLog', 'visitLog', 'weightRecord', 'dietRecord'
  ]

  const exportData = {}
  for (const table of tables) {
    try {
      exportData[table] = await prisma[table].findMany()
    } catch (e) {
      exportData[table] = []
    }
  }

  const filename = `prisma-backup-${timestamp}.json`
  const filepath = path.join(backupsDir, filename)
  await fs.promises.writeFile(filepath, JSON.stringify(exportData, null, 2))
  
  console.log(`‚úÖ Prisma Â§á‰ªΩÂÆåÊàê: ${filename}`)
  return filename
}

/**
 * SQLite Â§á‰ªΩ - ‰ΩøÁî® VACUUM INTO ÊàñÊñá‰ª∂Â§çÂà∂
 */
const backupSqlite = async () => {
  const { PrismaClient } = require('@prisma/client')
  const prisma = global.prisma || new PrismaClient()

  const backupsDir = getBackupsDir()
  ensureDir(backupsDir)

  const timestamp = new Date().toISOString().replace(/[-:T.Z]/g, '').slice(0, 14)
  const config = parseConnectionString()
  
  if (!config || config.type !== 'sqlite') {
    throw new Error('Êó†ÊïàÁöÑ SQLite ÈÖçÁΩÆ')
  }

  const dbPath = path.isAbsolute(config.path) 
    ? config.path 
    : path.join(__dirname, '..', '..', 'prisma', config.path.replace('./', ''))
  
  const basename = path.basename(dbPath).replace('.db', '')
  const filename = `${basename}-${timestamp}.db`
  const target = path.join(backupsDir, filename)

  try {
    await prisma.$executeRawUnsafe(`PRAGMA wal_checkpoint(TRUNCATE)`)
    const escaped = target.replace(/'/g, "''")
    await prisma.$executeRawUnsafe(`VACUUM INTO '${escaped}'`)
    await fs.promises.access(target)
  } catch {
    await fs.promises.copyFile(dbPath, target)
  }

  console.log(`‚úÖ SQLite Â§á‰ªΩÂÆåÊàê: ${filename}`)
  return filename
}

/**
 * Áªü‰∏ÄÂ§á‰ªΩÊé•Âè£ - Ëá™Âä®Ê£ÄÊµãÊï∞ÊçÆÂ∫ìÁ±ªÂûã
 */
const backupOnce = async () => {
  const dbType = getDatabaseType()
  
  switch (dbType) {
    case 'postgresql':
      return await backupPostgres()
    case 'sqlite':
      return await backupSqlite()
    default:
      throw new Error(`‰∏çÊîØÊåÅÁöÑÊï∞ÊçÆÂ∫ìÁ±ªÂûã: ${dbType}`)
  }
}

/**
 * PostgreSQL ÊÅ¢Â§ç
 */
const restorePostgres = async (filename) => {
  const config = parseConnectionString()
  if (!config || config.type !== 'postgresql') {
    throw new Error('Êó†ÊïàÁöÑ PostgreSQL ÈÖçÁΩÆ')
  }

  const backupsDir = getBackupsDir()
  const filepath = path.join(backupsDir, filename)

  if (!fs.existsSync(filepath)) {
    throw new Error(`Â§á‰ªΩÊñá‰ª∂‰∏çÂ≠òÂú®: ${filename}`)
  }

  const env = {
    ...process.env,
    PGPASSWORD: config.password,
    PGHOST: config.host,
    PGPORT: config.port,
    PGUSER: config.user,
    PGDATABASE: config.database
  }

  if (filename.endsWith('.sql')) {
    try {
      await execAsync(`psql < "${filepath}"`, { env, maxBuffer: 100 * 1024 * 1024 })
      console.log(`‚úÖ PostgreSQL ÊÅ¢Â§çÂÆåÊàê: ${filename}`)
      return true
    } catch (error) {
      throw new Error(`ÊÅ¢Â§çÂ§±Ë¥•: ${error.message}`)
    }
  }

  if (filename.endsWith('.json')) {
    return await restoreWithPrisma(filepath)
  }

  throw new Error('‰∏çÊîØÊåÅÁöÑÂ§á‰ªΩÊñá‰ª∂Ê†ºÂºè')
}

/**
 * Prisma ÊÅ¢Â§ç - ‰ªé JSON ÂØºÂÖ•Êï∞ÊçÆ
 */
const restoreWithPrisma = async (filepath) => {
  const { PrismaClient } = require('@prisma/client')
  const prisma = global.prisma || new PrismaClient()

  const data = JSON.parse(await fs.promises.readFile(filepath, 'utf-8'))

  const deleteOrder = [
    'commentLike', 'bookmark', 'bookmarkCollection', 'comment',
    'columnNode', 'column', 'post', 'tag', 'category',
    'resource', 'project', 'siteSettings', 'profile',
    'operationLog', 'visitLog', 'weightRecord', 'dietRecord', 'user'
  ]

  const insertOrder = [
    'user', 'category', 'tag', 'siteSettings', 'profile',
    'resource', 'project', 'column', 'post', 'comment',
    'commentLike', 'bookmarkCollection', 'bookmark', 'columnNode',
    'operationLog', 'visitLog', 'weightRecord', 'dietRecord'
  ]

  await prisma.$transaction(async (tx) => {
    for (const table of deleteOrder) {
      try { await tx[table].deleteMany() } catch (e) {}
    }

    for (const table of insertOrder) {
      const records = data[table] || []
      for (const record of records) {
        try {
          const processed = { ...record }
          for (const key of Object.keys(processed)) {
            if (processed[key] && typeof processed[key] === 'string' &&
                /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}/.test(processed[key])) {
              processed[key] = new Date(processed[key])
            }
          }
          await tx[table].create({ data: processed })
        } catch (e) {
          console.warn(`Ë∑≥Ëøá ${table} ËÆ∞ÂΩï:`, e.message)
        }
      }
    }
  })

  console.log(`‚úÖ Prisma ÊÅ¢Â§çÂÆåÊàê`)
  return true
}

/**
 * SQLite ÊÅ¢Â§ç
 */
const restoreSqlite = async (filename) => {
  const { PrismaClient } = require('@prisma/client')
  const prisma = global.prisma || new PrismaClient()

  const config = parseConnectionString()
  if (!config || config.type !== 'sqlite') {
    throw new Error('Êó†ÊïàÁöÑ SQLite ÈÖçÁΩÆ')
  }

  const backupsDir = getBackupsDir()
  const source = path.join(backupsDir, filename)
  const dbPath = path.isAbsolute(config.path) 
    ? config.path 
    : path.join(__dirname, '..', '..', 'prisma', config.path.replace('./', ''))

  if (!fs.existsSync(source)) {
    throw new Error(`Â§á‰ªΩÊñá‰ª∂‰∏çÂ≠òÂú®: ${filename}`)
  }

  await prisma.$disconnect()
  await fs.promises.copyFile(source, dbPath)
  await prisma.$connect()

  console.log(`‚úÖ SQLite ÊÅ¢Â§çÂÆåÊàê: ${filename}`)
  return true
}

/**
 * Áªü‰∏ÄÊÅ¢Â§çÊé•Âè£
 */
const restoreBackup = async (filename) => {
  const dbType = getDatabaseType()
  
  // JSON Êñá‰ª∂ÂèØ‰ª•Ë∑®Êï∞ÊçÆÂ∫ìÁ±ªÂûãÊÅ¢Â§ç
  if (filename.endsWith('.json')) {
    const backupsDir = getBackupsDir()
    return await restoreWithPrisma(path.join(backupsDir, filename))
  }
  
  switch (dbType) {
    case 'postgresql':
      return await restorePostgres(filename)
    case 'sqlite':
      return await restoreSqlite(filename)
    default:
      throw new Error(`‰∏çÊîØÊåÅÁöÑÊï∞ÊçÆÂ∫ìÁ±ªÂûã: ${dbType}`)
  }
}

/**
 * ÂàóÂá∫ÊâÄÊúâÂ§á‰ªΩ
 */
const listBackups = async () => {
  const dir = getBackupsDir()
  ensureDir(dir)

  const files = await fs.promises.readdir(dir)
  const backups = []

  for (const f of files) {
    if (!f.endsWith('.db') && !f.endsWith('.sql') && !f.endsWith('.json')) continue
    const p = path.join(dir, f)
    const stat = await fs.promises.stat(p)
    backups.push({
      file: f,
      size: stat.size,
      createdAt: stat.mtime,
      type: f.endsWith('.sql') ? 'postgresql' : f.endsWith('.json') ? 'prisma' : 'sqlite'
    })
  }

  return backups.sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt))
}

const retentionDays = () => {
  const v = parseInt(process.env.BACKUP_RETENTION_DAYS || '7', 10)
  return isNaN(v) ? 7 : Math.max(0, v)
}

const cleanupBackups = async () => {
  const dir = getBackupsDir()
  ensureDir(dir)

  const files = await fs.promises.readdir(dir)
  const now = Date.now()
  const days = retentionDays()
  const keepMs = days * 24 * 60 * 60 * 1000
  
  let deleted = 0
  for (const f of files) {
    if (!f.endsWith('.db') && !f.endsWith('.sql') && !f.endsWith('.json')) continue
    const p = path.join(dir, f)
    const stat = await fs.promises.stat(p)
    if (now - stat.mtimeMs > keepMs) {
      await fs.promises.unlink(p)
      deleted++
    }
  }

  if (deleted > 0) {
    console.log(`üóëÔ∏è Ê∏ÖÁêÜ‰∫Ü ${deleted} ‰∏™ËøáÊúüÂ§á‰ªΩ`)
  }
}

const parseSchedule = () => {
  const s = process.env.BACKUP_SCHEDULE || '04:00'
  const m = /^([01]?\d|2[0-3]):([0-5]\d)$/.exec(s)
  const h = m ? parseInt(m[1], 10) : 4
  const min = m ? parseInt(m[2], 10) : 0
  return { h, min }
}

const msUntilNext = (h, min) => {
  const now = new Date()
  const next = new Date(now)
  next.setHours(h, min, 0, 0)
  if (next <= now) next.setDate(next.getDate() + 1)
  return next - now
}

const runCycle = async () => {
  try {
    await backupOnce()
    await cleanupBackups()
  } catch (e) {
    console.error('Â§á‰ªΩÂ§±Ë¥•:', e.message)
  }
}

const scheduleDaily = () => {
  const { h, min } = parseSchedule()
  const firstDelay = msUntilNext(h, min)
  
  console.log(`üìÖ Â§á‰ªΩÂ∑≤Ë∞ÉÂ∫¶: ÊØèÂ§© ${String(h).padStart(2, '0')}:${String(min).padStart(2, '0')}`)
  console.log(`   Êï∞ÊçÆÂ∫ìÁ±ªÂûã: ${getDatabaseType()}`)
  
  setTimeout(() => {
    runCycle()
    setInterval(runCycle, 24 * 60 * 60 * 1000)
  }, firstDelay)
}

module.exports = {
  backupOnce,
  restoreBackup,
  cleanupBackups,
  listBackups,
  scheduleDaily,
  getDatabaseType,
  parseConnectionString
}
